{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "\n",
    "#### In this section, we will look at what Transformer models can do and use our first tool from the ðŸ¤— Transformers library: the pipeline() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various tasks in NLP that help us gain insights from text data. Some common examples include:\n",
    "\n",
    "1. Classifying whole sentences: This involves determining the sentiment of a review, identifying if an email is spam, checking the grammatical correctness of a sentence, or establishing logical relationships between two sentences.\n",
    "\n",
    "2. Classifying each word in a sentence: This task involves recognizing the grammatical components of a sentence, such as nouns, verbs, and adjectives. It also includes identifying named entities like people, locations, and organizations.\n",
    "\n",
    "3. Generating text content: NLP can be used to automatically generate text by completing prompts or filling in masked words in a given text.\n",
    "\n",
    "4. Extracting answers from text: Given a question and a context, NLP algorithms can extract the relevant answer from the text based on the information provided.\n",
    "\n",
    "5. Generating new sentences: NLP models can translate text from one language to another or summarize lengthy texts into concise summaries.\n",
    "\n",
    "NLP is not limited to written text alone. It also tackles complex challenges in speech recognition and computer vision. For example, it can generate transcriptions of audio samples or provide descriptions of images.\n",
    "\n",
    "However, NLP poses unique challenges because computers process information differently from humans. While humans can easily understand the meaning of a sentence or determine the similarity between two sentences, ML models struggle with these tasks. Text data needs to be processed in a way that allows the model to learn effectively. Due to the complexity of language, careful consideration must be given to the methods used for text representation. Ongoing research in this field has led to the development of various techniques, which we will explore in the next chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9893580079078674},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformers, what can they do?\n",
    "\n",
    "# The most basic object in the ðŸ¤— Transformers library is the pipeline() function. \n",
    "# It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer:\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\"I've been waiting for a NLP course my whole life.\", \"I hate this so much!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, this pipeline selects a particular pretrained model that has been fine-tuned for sentiment analysis in English. \n",
    "\n",
    "The model is downloaded and cached when you create the classifier object. If you rerun the command, \n",
    "\n",
    "the cached model will be used instead and there is no need to download the model again.\n",
    "\n",
    "There are three main steps involved when you pass some text to a pipeline:\n",
    "\n",
    "1. The text is preprocessed into a format the model can understand.\n",
    "2. The preprocessed inputs are passed to the model.\n",
    "3. The predictions of the model are post-processed, so you can make sense of them.\n",
    "\n",
    "Some of the currently available pipelines are:\n",
    "\n",
    "- feature-extraction (get the vector representation of a text)\n",
    "- fill-mask\n",
    "- ner (named entity recognition)\n",
    "- question-answering\n",
    "- sentiment-analysis\n",
    "- summarization\n",
    "- text-generation\n",
    "- translation\n",
    "- zero-shot-classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBartForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBartForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\Hugging Face\\nlp-transformers-hf\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['politics', 'business', 'education'],\n",
       " 'scores': [0.3502453565597534, 0.3419712483882904, 0.3077833950519562]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero shot classification pipeline can be used to classify text sequences or text pairs in any zero-shot setting:\n",
    "# The zero-shot classification pipeline is a tool that allows you to specify which labels to use for the classification, \n",
    "# so you don't have to rely on the labels present in the training set.\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-cnn\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
